{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_table2(table2,column_name_old, column_name_new,delimiter, confounder_text):\n",
    "    \"\"\"\n",
    "    Dataframe preprocessing for tables from VigilApp. Splits by delimiter & transposes original table. Renames cols.\n",
    "    Deletes unnecessary string. Adds new row with confounder_text\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    table2 -- df to transpose\n",
    "    column_name_old, column_name_new -- col names\n",
    "    delimiter -- to split by\n",
    "    confounder_text -- text to add in new row\n",
    "    \n",
    "    Returns\n",
    "    \n",
    "    table2 -- modified df\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    table2 = table2[column_name_old].str.split(delimiter, expand=True).transpose() #one col is one future confounder table, split content by delimter (vals are all in one row, delimited), transpose\n",
    "    table2.columns = [column_name_new]\n",
    "    #table2.rename(columns={table2['1']: column_name_new}, inplace=True)#rename COL WITH HEADER 1 to more intelligible\n",
    "    table2[column_name_new] = table2[column_name_new].astype(str) + delimiter #change to str (int in some cases), add delimiter\n",
    "    table2[column_name_new] = table2[column_name_new].str.replace(r'More results Show/Hide', '') #remove string artefact\n",
    "    new_row_table2 = {column_name_new:confounder_text} #new row is confounder info text, first col\n",
    "    table2 = table2.append(new_row_table2, ignore_index=True) #append it\n",
    "    \n",
    "    return table2\n",
    "\n",
    "def drop_row(df,column_name,value):\n",
    "    \n",
    "    \"\"\"\n",
    "    Removes rows where value.\n",
    "    \n",
    "    Input:\n",
    "    df -- dataframe to modify\n",
    "    column_name -- loc of value\n",
    "    value -- value of rows to remove\n",
    "    \n",
    "    Returns\n",
    "    \n",
    "    df -- modified df\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    index_to_remove = df[df[column_name] == value].index #get index of row with )\n",
    "    df.drop(index_to_remove, inplace=True) #drop above\n",
    "    return df\n",
    "\n",
    "def initiate_driver(path_to_driver, website_address):\n",
    "    \"\"\" Initiates chrome webdriver with website_address based on driver path\n",
    "    \n",
    "    On windows: provide chromedriver.exe location (here in current dir) | mac: provide binary path to chromedriver: chromedriver executable file must be moved to usr/local/bin/chromedriver, eg. with command mv chromedriver /usr/local/bin;  \n",
    "    Ipnut:\n",
    "    path_to_driver, website_address (str)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    chromedriver_path = path_to_driver\n",
    "    driver = webdriver.Chrome(chromedriver_path)\n",
    "\n",
    "    website_address = website_address\n",
    "    sleep(2)\n",
    "    driver.get(website_address)\n",
    "    sleep(random.randint(5,6)) #wait until fully loaded, alternative: WebDriverWait, check ways to apply selenium waits to iframe\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def search_enter_keys(path,keys_to_send):\n",
    "\n",
    "    \"\"\"Looks for element by xpath. Sends keys.\n",
    "\n",
    "    \"\"\"\n",
    "    path = path\n",
    "    field = driver.find_element_by_xpath(path) \n",
    "    field.send_keys(keys_to_send) \n",
    "    sleep(random.randint(1,3))\n",
    "\n",
    "    return driver\n",
    "\n",
    "\n",
    "def scrape_signal(path_to_signal, signal_col_name, events, event):\n",
    "\n",
    "    \"\"\"Switches to second tab, grabs text in path_to_signal, inputs text in signal_col_name:\n",
    "\n",
    "    Input:\n",
    "    path_to_signal -- path to info in vigilapp (wether event unrelated or putative adverse event)\n",
    "    signal_col_name -- name of col in events df to write signal info into\n",
    "    events -- df with events list & drug names, has 'event' col\n",
    "    event -- row value of col 'event' in events df where to write signal info\n",
    "    \n",
    "    Returns signal (ADR or unrelated) as per text in vigilapp \n",
    "\n",
    "    \"\"\"\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "    text = WebDriverWait(driver,20).until(EC.presence_of_element_located((By.XPATH,path_to_signal)))\n",
    "    events.loc[(events['event'] == event), signal_col_name] = text.text\n",
    "    signal = text.text\n",
    "    \n",
    "    return driver,signal\n",
    "\n",
    "def click_all_buttons(button_text):\n",
    "\n",
    "    \"\"\"Clicks all the button with button_text\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    shows = driver.find_elements_by_link_text(button_text)\n",
    "    sleep(4)\n",
    "\n",
    "    for show in shows:\n",
    "        show.click()\n",
    "        sleep(3)\n",
    "\n",
    "    return driver\n",
    "\n",
    "def find_all_tables(driver, table_tag):\n",
    "    \"\"\"Gets all the tables in BeautifulSoup html_page in driver source page\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    html_page = driver.page_source\n",
    "    soup = BeautifulSoup(html_page, 'lxml')\n",
    "\n",
    "    tables = soup.find_all(table_tag)\n",
    "    all_tables = pd.read_html(str(tables))\n",
    "    \n",
    "    \n",
    "    return all_tables\n",
    "\n",
    "def process_tables(all_tables):\n",
    "    \"\"\"Get three first tables, table 3: transpose, assign new header (first row) \"\"\"\n",
    "    \n",
    "    table0 = all_tables[0]\n",
    "    table1 = all_tables[1]\n",
    "    table2 = all_tables[2].transpose()\n",
    "    \n",
    "    new_header = table2.iloc[0] #grab the first row for the header\n",
    "    table2 = table2[1:] #take the data less the header row\n",
    "    table2.columns = new_header #set the header row as the df header\n",
    "    \n",
    "    return table0,table1,table2\n",
    "\n",
    "def get_DPA_indicators(DA_table,contingency_table):\n",
    "\n",
    "    \"\"\"Gets PRR, chi-squared and no of reports for DPA evaluation (from DA_table, contingency_table)\"\"\"\n",
    "\n",
    "    PRR = DA_table.Value[3]\n",
    "    chi = DA_table.Value[1]\n",
    "    no_reports = (contingency_table[contingency_table.columns[1]][0]).replace(r'DE','')\n",
    "\n",
    "    return PRR, chi, no_reports\n",
    "\n",
    "def add_interpretation(tableDA, signal,text,suffix_related,suffix_unrelated):\n",
    "    \n",
    "    \"\"\" Add row to DPA table explaining how to interpret results, depending on the signal.\n",
    "    Text is a base info string, suffixes depend on signal evaluation\n",
    "    \n",
    "    \"\"\"\n",
    "    if signal == 'ADVERSE DRUG REACTION':\n",
    "        new_row_tableDA = {'Disproportionality indicators':text + suffix_related}\n",
    "        tableDA = tableDA.append(new_row_tableDA, ignore_index=True)\n",
    "\n",
    "    if signal == 'unrelated':\n",
    "        new_row_tableDA = {'Disproportionality indicators':text + suffix_unrelated}\n",
    "        tableDA = tableDA.append(new_row_tableDA, ignore_index=True)\n",
    "        \n",
    "    return tableDA\n",
    "\n",
    "def add_rows_contingency(first_col_name,table_contingency,formulaPRR,formula_chi):\n",
    "\n",
    "    \"\"\"Add remaining info on formulas for PRR, chi-squared used for calculations. Adding into first col.\n",
    "    \"\"\"\n",
    "    new_row_table0 = {first_col_name:formulaPRR}\n",
    "    table_contingency = table_contingency.append(new_row_table0, ignore_index=True)\n",
    "    new_row_table0b = {first_col_name:formula_chi}\n",
    "    table_contingency = table_contingency.append(new_row_table0b, ignore_index=True)\n",
    "\n",
    "    return table_contingency\n",
    "\n",
    "def write_to_excel(path,engine,tables,table_names):\n",
    "\n",
    "    \"\"\"Write all DPA analysis to one excel with multiple sheets\"\"\"\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine\n",
    "    writer = pd.ExcelWriter(path, engine=engine)\n",
    "\n",
    "    for table, table_name in zip(tables, table_names):\n",
    "        # Write each dataframe to a different worksheet.\n",
    "        table.to_excel(writer, sheet_name=table_name, index=False)\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adrs_dir = os.path.join(os.getcwd(), 'signals')\n",
    "da = os.path.join(os.getcwd(), 'DA')\n",
    "dirs = [all_adrs_dir,da]\n",
    "for directory in dirs:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df with events (per drug)\n",
    "events = pd.read_excel('events.xlsx') #list of events per drug\n",
    "events['event'] = events['event'].str.strip() #copied from VigilApp, have trailing spaces\n",
    "\n",
    "references = pd.read_excel('references.xlsx') #needs .xlsx with ref to append\n",
    "\n",
    "formulaPRR = 'Additional explanation: calculations are made using following formulas: PRR = ( DE / D ) / (dE/ d)'\n",
    "formula_chi = 'Chi squared with Yate\\'s correction = N * ( | DE*de â€“ dE*De | - N/2 )2/ (D * d * E * e)'\n",
    "confounder_text = 'Aditional explanation: this sheet contains possible confounders: ie. drugs, events, indications, ages or sex that are most frequent among the subpopulation selected for this drug:event pair. You can use them to refine the subpopulations you want to compare (e.g., unmasking signals by using (NOT this drug)) or include them into the background correction'\n",
    "table_names = ['Contingency Table', 'DA results','Gender Distribution', 'Age Distribution', 'Top Drugs', 'Top Product Names', 'Top Drug Classes', 'Top ADRs', 'Top Indications', 'References']\n",
    "\n",
    "#only use when events sorted by rel/unrel for unrel events\n",
    "text = 'Additional explanation: interpretation of the DA results: According to the criteria by Evans 2001, which requires a report count > 3 (this combination: {0}) and a PRR > 2 (here: {1}) and a Chi-squared > 4 (here: {2}) this drug and event are '\n",
    "suffix_related = 'statistically significantly related (=putative ADVERSE DRUG REACTION).'\n",
    "suffix_unrelated = 'probably unrelated.'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event, drug_name in zip(events.event, events.drug_name):\n",
    "    \n",
    "    driver = initiate_driver('/usr/local/bin/chromedriver', 'https://openvigil.pharmacology.uni-kiel.de/openvigilfda.php')\n",
    "    driver.find_element_by_xpath('/html/body/form/ul/ul[2]/li/input').click() #checkbox for DPA as method of data analysis\n",
    "    \n",
    "    driver = search_enter_keys('//input[@name=\"wdrugname2\"]', drug_name) #input: drug name\n",
    "    driver = search_enter_keys('//input[@name=\"waevent2\"]', event) # input: event\n",
    "    \n",
    "    driver.find_element_by_xpath('//input[@name=\"query\"]').click() #query\n",
    "    sleep(7)\n",
    "    \n",
    "    driver,signal = scrape_signal(\"/html/body/strong\", 'signal', events, event) #write info on signal (unrelated or ADR)\n",
    "    \n",
    "    \n",
    "    driver = click_all_buttons(\"Show\") #click all show buttons\n",
    "    \n",
    "    all_tables = find_all_tables(driver,'table') #get all tables on the page\n",
    "\n",
    "    driver.quit() #close window\n",
    "    \n",
    "    table0,table1,table2 = process_tables(all_tables) #get first three tables, clean table3\n",
    "    \n",
    "    PRR,chi,no_reports = get_DPA_indicators(table1,table0) #get DPA indicators from DPA & contingency tables\n",
    "    \n",
    "    text_to_add = text.format(no_reports, PRR, chi)#current DPA indicatiors - put in text\n",
    "    \n",
    "    table1 = add_interpretation(table1,signal,text_to_add,suffix_related,suffix_unrelated )  #add additional info on interpretation of signal to DPA table\n",
    "\n",
    "    table0 = add_rows_contingency('Groups',table0,formulaPRR,formula_chi) #add remaining explanation info to contingency table\n",
    "    \n",
    "    #get all additional tables (confounders) as result of DPA analysis by transposing table2\n",
    "    \n",
    "    #age distribution\n",
    "    age = clean_data_table2(table2, 'Age distributionAge (Number of reports)', 'Age (number of reports)', ')', confounder_text)\n",
    "    age = drop_row(age, 'Age (number of reports)', ')') \n",
    "    \n",
    "    #top confounding drugs \n",
    "    drugs_top = clean_data_table2(table2, 'Top drugsGeneric Name (Number of reports)', 'Top drugs by Generic Name (number of reports)', ')', confounder_text)\n",
    "    drugs_top = drop_row(drugs_top, 'Top drugs by Generic Name (number of reports)', ')' )\n",
    "    \n",
    "    #top confounding products\n",
    "    top_prod_names = clean_data_table2(table2, 'Top medicinalproductsProductname (Number of reports)', 'Top medicinal products by Product name (Number of reports)', ')',confounder_text)\n",
    "    top_prod_names = drop_row(top_prod_names, 'Top medicinal products by Product name (Number of reports)', ')')\n",
    "    \n",
    "    #top confounding drug clases\n",
    "    top_drug_clases = clean_data_table2(table2, 'Top drugclasses MoAMechanism of Action (Number of reports)', 'Top drug classes by Mechanism of Action [MoA] (number of reports)', ')', confounder_text)\n",
    "    top_drug_clases = drop_row(top_drug_clases, 'Top drug classes by Mechanism of Action [MoA] (number of reports)', ')')\n",
    "    \n",
    "    #top confounding events\n",
    "    top_events = clean_data_table2(table2, 'Top adverse eventsEvent (Number of reports)', 'Top adverse events by Event (number of reports)', ')',confounder_text)\n",
    "    top_events = drop_row(top_events, 'Top adverse events by Event (number of reports)', ')')\n",
    "    \n",
    "    #top confounding indications\n",
    "    top_indicat = clean_data_table2(table2, 'Top indicationsIndication (Number of reports)', 'Top indications by Indication (number of reports)', ')',confounder_text)\n",
    "    top_indicat = drop_row(top_indicat, 'Top indications by Indication (number of reports)', ')')\n",
    "\n",
    "    #gender distribution\n",
    "    gender = clean_data_table2(table2,'Gender distribution','Gender distribution', 'le', confounder_text )\n",
    "    gender = drop_row(gender, 'Gender distribution', 'le' )\n",
    "    \n",
    "    tables = [table0,table1,gender,age,drugs_top,top_prod_names,top_drug_clases,top_events,top_indicat,references]\n",
    "    \n",
    "    #write all to excel with multiple sheets\n",
    "    write_to_excel(os.path.join(da,'DA_{0}_{1}.xlsx'.format(drug_name,event)),'xlsxwriter',tables,table_names)\n",
    "    \n",
    "    \n",
    "#change \"ADR\" to \"Related\" to follow related/unrelated convention\n",
    "events.loc[(events['signal'] == 'ADVERSE DRUG REACTION'), 'signal'] = 'Related'\n",
    "events['signal'] = events['signal'].str.capitalize() #capitalise unrelated\n",
    "   \n",
    "events.to_excel('events_signals.xlsx', index=False) #save to excel events+drugs+signals\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
